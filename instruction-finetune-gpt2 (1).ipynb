{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --q datasets\n!pip install --q --upgrade trl\n!pip install --upgrade accelerate\n!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:20:32.801632Z","iopub.execute_input":"2024-12-23T04:20:32.801973Z","iopub.status.idle":"2024-12-23T04:21:08.510544Z","shell.execute_reply.started":"2024-12-23T04:20:32.801939Z","shell.execute_reply":"2024-12-23T04:21:08.509663Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nCollecting accelerate\n  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.26.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.1.1\n    Uninstalling accelerate-1.1.1:\n      Successfully uninstalled accelerate-1.1.1\nSuccessfully installed accelerate-1.2.1\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained('NlpHUST/gpt2-vietnamese')\nmodel = GPT2LMHeadModel.from_pretrained('NlpHUST/gpt2-vietnamese')\n\ntext = \"Vi·ªát Nam l√† qu·ªëc gia c√≥\"\ninput_ids = tokenizer.encode(text, return_tensors='pt')\nmax_length = 100\n\nsample_outputs = model.generate(input_ids,pad_token_id=tokenizer.eos_token_id,\n                                   do_sample=True,\n                                   max_length=max_length,\n                                   min_length=max_length,\n                                   top_k=40,\n                                   num_beams=5,\n                                   early_stopping=True,\n                                   no_repeat_ngram_size=2,\n                                   num_return_sequences=3)\n\nfor i, sample_output in enumerate(sample_outputs):\n    print(\">> Generated text {}\\n\\n{}\".format(i+1, tokenizer.decode(sample_output.tolist())))\n    print('\\n---')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:08.512856Z","iopub.execute_input":"2024-12-23T04:21:08.513248Z","iopub.status.idle":"2024-12-23T04:21:38.742599Z","shell.execute_reply.started":"2024-12-23T04:21:08.513208Z","shell.execute_reply":"2024-12-23T04:21:38.741690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfcbf23ce08d4c94852d7775693bfed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/854k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b085103e237f457397afc8e0069525f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/512k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1750ef5d0484e998511f677a09f21f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2974f88de2425ead82444afeeb7a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6731727014142bfbafa91ed683627ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36bb844d0acd4b2f8d33a47c4b2e1bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9ee439e4934c4491d443415a7a9d4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d849175b43064f36b0d5e34844a0cb4b"}},"metadata":{}},{"name":"stdout","text":">> Generated text 1\n\nVi·ªát Nam l√† qu·ªëc gia c√≥ n·ªÅn kinh t·∫ø h√†ng ƒë·∫ßu tr√™n th·∫ø gi·ªõi v√† ƒë∆∞·ª£c ƒë√°nh gi√° l√† m·ªôt trong nh·ªØng th·ªã tr∆∞·ªùng xu·∫•t kh·∫©u l·ªõn nh·∫•t c·ªßa Vi·ªát Nam.\nTheo s·ªë li·ªáu th·ªëng k√™ c·ªßa T·ªïng c·ª•c H·∫£i quan, trong 6 th√°ng ƒë·∫ßu nƒÉm 2018, t·ªïng kim ng·∫°ch xu·∫•t nh·∫≠p kh·∫©u h√†ng h√≥a c·ªßa c·∫£ n∆∞·ªõc ∆∞·ªõc ƒë·∫°t 2,12 t·ª∑ USD, tƒÉng 11,4% so v·ªõi c√πng k·ª≥ nƒÉm 2017. Trong ƒë√≥, xu·∫•t si√™u ƒë·∫°t 1,6 t·ª∑ ƒë√¥ la M·ªπ, chi·∫øm 13,2\n\n---\n>> Generated text 2\n\nVi·ªát Nam l√† qu·ªëc gia c√≥ n·ªÅn kinh t·∫ø h√†ng ƒë·∫ßu tr√™n th·∫ø gi·ªõi v√† ƒë∆∞·ª£c ƒë√°nh gi√° l√† m·ªôt trong nh·ªØng th·ªã tr∆∞·ªùng xu·∫•t kh·∫©u l·ªõn nh·∫•t c·ªßa Vi·ªát Nam.\nTheo s·ªë li·ªáu th·ªëng k√™ c·ªßa T·ªïng c·ª•c H·∫£i quan, trong 6 th√°ng ƒë·∫ßu nƒÉm 2018, t·ªïng kim ng·∫°ch xu·∫•t nh·∫≠p kh·∫©u h√†ng h√≥a c·ªßa c·∫£ n∆∞·ªõc ∆∞·ªõc ƒë·∫°t 2,12 t·ª∑ USD, tƒÉng 11,4% so v·ªõi c√πng k·ª≥ nƒÉm 2017. Trong ƒë√≥, xu·∫•t si√™u ƒë·∫°t 1,6 t·ª∑ ƒë√¥ la M·ªπ, chi·∫øm 5,8\n\n---\n>> Generated text 3\n\nVi·ªát Nam l√† qu·ªëc gia c√≥ n·ªÅn kinh t·∫ø h√†ng ƒë·∫ßu tr√™n th·∫ø gi·ªõi v√† ƒë∆∞·ª£c ƒë√°nh gi√° l√† m·ªôt trong nh·ªØng th·ªã tr∆∞·ªùng xu·∫•t kh·∫©u l·ªõn nh·∫•t c·ªßa Vi·ªát Nam.\nTheo s·ªë li·ªáu th·ªëng k√™ c·ªßa T·ªïng c·ª•c H·∫£i quan, trong 6 th√°ng ƒë·∫ßu nƒÉm 2018, t·ªïng kim ng·∫°ch xu·∫•t nh·∫≠p kh·∫©u h√†ng h√≥a c·ªßa c·∫£ n∆∞·ªõc ∆∞·ªõc ƒë·∫°t 2,12 t·ª∑ USD, tƒÉng 11,4% so v·ªõi c√πng k·ª≥ nƒÉm 2017. Trong ƒë√≥, xu·∫•t si√™u ƒë·∫°t 1,6 t·ª∑ ƒë√¥ la M·ªπ, chi·∫øm 5,7\n\n---\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ƒê·∫øm s·ªë l∆∞·ª£ng tham s·ªë c·ªßa model\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams_count = sum([torch.numel(p) for p in model_parameters])\n\nprint(f\"Total trainable parameters: {params_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:38.743710Z","iopub.execute_input":"2024-12-23T04:21:38.744201Z","iopub.status.idle":"2024-12-23T04:21:38.750399Z","shell.execute_reply.started":"2024-12-23T04:21:38.744173Z","shell.execute_reply":"2024-12-23T04:21:38.749546Z"}},"outputs":[{"name":"stdout","text":"Total trainable parameters: 124439808\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\n\nfrom datasets import load_dataset\nopen_instruct_dataset = load_dataset(\"5CD-AI/Vietnamese-Ecommerce-Alpaca\", split=\"train\")\n\nmax_seq_len = 100\ntotal_data_points = len(open_instruct_dataset)\nsample_size = 10000\nrandom_indices = random.sample(range(total_data_points), sample_size)\n\n\n\n# filter dataset to rows where the entire context length is less than or equal to max_seq_len,\n# which is the size of the DeciLM-6B context window\n\nopen_instruct_dataset = open_instruct_dataset.select(random_indices)\n\ndataset = open_instruct_dataset.filter(\n    lambda example: (len(tokenizer(example.get(\"instruction\", \"\"), truncation=True)[\"input_ids\"]) +\n                     len(tokenizer(example.get(\"input\", \"\"), truncation=True)[\"input_ids\"]) +\n                     len(tokenizer(example.get(\"output\", \"\"), truncation=True)[\"input_ids\"])) <= max_seq_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:38.751761Z","iopub.execute_input":"2024-12-23T04:21:38.752116Z","iopub.status.idle":"2024-12-23T04:21:59.302798Z","shell.execute_reply.started":"2024-12-23T04:21:38.752078Z","shell.execute_reply":"2024-12-23T04:21:59.301866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ecommerce_alpaca.json:   0%|          | 0.00/84.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c411bb3045445ca4cf84ed7d15fb1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/69303 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9c67f815334ce6bbbac0f4c41a6223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ddde04fe6a3404bb66e47668a537c7d"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:59.304855Z","iopub.execute_input":"2024-12-23T04:21:59.305131Z","iopub.status.idle":"2024-12-23T04:21:59.310888Z","shell.execute_reply.started":"2024-12-23T04:21:59.305104Z","shell.execute_reply":"2024-12-23T04:21:59.310002Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'instruction', 'input'],\n    num_rows: 2377\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def format_row_as_instruction_prompt(example):\n    has_input = example.get('input', None) is not None\n\n    if has_input:\n        primer_prompt = (\"D∆∞·ªõi ƒë√¢y l√† m·ªôt h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•, k√®m theo m·ªôt ƒë·∫ßu v√†o \"\n                         \"cung c·∫•p th√™m ng·ªØ c·∫£nh. Vi·∫øt m·ªôt ph·∫£n h·ªìi ho√†n ch·ªânh ƒë·ªÉ th·ª±c hi·ªán y√™u c·∫ßu.\")\n        input_template = f\"### ƒê·∫ßu v√†o: \\n{example['input']}\\n\\n\"\n    else:\n        primer_prompt = (\"D∆∞·ªõi ƒë√¢y l√† m·ªôt h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•. \"\n                         \"Vi·∫øt m·ªôt ph·∫£n h·ªìi ho√†n ch·ªânh ƒë·ªÉ th·ª±c hi·ªán y√™u c·∫ßu.\")\n        input_template = \"\"\n\n    instruction_template = f\"### H∆∞·ªõng d·∫´n: \\n{example['instruction']}\\n\\n\"\n\n    if example.get('output', None):\n        response_template = f\"### Ph·∫£n h·ªìi: \\n{example['output']}\\n\\n\"\n    else:\n        response_template = \"\"\n\n    # Wrap the resulting string in a list\n    return [f\"{primer_prompt}\\n\\n{instruction_template}{input_template}{response_template}\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:59.311894Z","iopub.execute_input":"2024-12-23T04:21:59.312147Z","iopub.status.idle":"2024-12-23T04:22:01.311567Z","shell.execute_reply.started":"2024-12-23T04:21:59.312122Z","shell.execute_reply":"2024-12-23T04:22:01.310606Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(format_row_as_instruction_prompt(dataset[0])[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:01.312930Z","iopub.execute_input":"2024-12-23T04:22:01.313651Z","iopub.status.idle":"2024-12-23T04:22:01.323790Z","shell.execute_reply.started":"2024-12-23T04:22:01.313610Z","shell.execute_reply":"2024-12-23T04:22:01.322850Z"}},"outputs":[{"name":"stdout","text":"D∆∞·ªõi ƒë√¢y l√† m·ªôt h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•, k√®m theo m·ªôt ƒë·∫ßu v√†o cung c·∫•p th√™m ng·ªØ c·∫£nh. Vi·∫øt m·ªôt ph·∫£n h·ªìi ho√†n ch·ªânh ƒë·ªÉ th·ª±c hi·ªán y√™u c·∫ßu.\n\n### H∆∞·ªõng d·∫´n: \nK·∫øt h·ª£p hai m·∫£ng sau kh√¥ng c√≥ tr√πng l·∫∑p [\"D√¢y gi√†y th·ªÉ thao\", \"Mi·∫øng l√≥t gi√†y\", \"B√†n ch·∫£i ƒë√°nh gi√†y\"] v√† [\"Mi·∫øng l√≥t gi√†y\", \"B√†n ch·∫£i ƒë√°nh gi√†y\", \"M√≥c kh√≥a gi√†y\"]\n\n### ƒê·∫ßu v√†o: \n\n\n### Ph·∫£n h·ªìi: \nSau khi k·∫øt h·ª£p hai m·∫£ng m√† kh√¥ng c√≥ s·ª± tr√πng l·∫∑p, m·∫£ng thu ƒë∆∞·ª£c l√†: [\"D√¢y gi√†y th·ªÉ thao\", \"Mi·∫øng l√≥t gi√†y\", \"B√†n ch·∫£i ƒë√°nh gi√†y\", \"M√≥c kh√≥a gi√†y\"]\n\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n\nresponse_template = \"### Ph·∫£n h·ªìi:\"\ncollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:01.325114Z","iopub.execute_input":"2024-12-23T04:22:01.325423Z","iopub.status.idle":"2024-12-23T04:22:03.762713Z","shell.execute_reply.started":"2024-12-23T04:22:01.325398Z","shell.execute_reply":"2024-12-23T04:22:03.761789Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:03.763823Z","iopub.execute_input":"2024-12-23T04:22:03.764092Z","iopub.status.idle":"2024-12-23T04:22:03.778852Z","shell.execute_reply.started":"2024-12-23T04:22:03.764065Z","shell.execute_reply":"2024-12-23T04:22:03.778150Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.1, random_state=42)\ntrain_dataset = dataset.select(train_indices)\nval_dataset = dataset.select(val_indices)\n\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Format the Dataset\ndef format_dataset(dataset):\n    \"\"\"\n    Format each row in the dataset using the format_row_as_instruction_prompt function\n    and return a Hugging Face Dataset object.\n    \"\"\"\n    # Create a dictionary to store formatted data\n    formatted_data = {\"text\": []}\n\n    for example in dataset:\n        formatted = format_row_as_instruction_prompt(example)[0]\n        formatted_data[\"text\"].append(formatted)\n\n    # Convert the dictionary into a Hugging Face Dataset\n    return Dataset.from_dict(formatted_data)\n\n\n# Step 2: Split the Dataset\ndef split_dataset(dataset, test_size=0.1, random_seed=42):\n    \"\"\"\n    Split the dataset into training and validation sets.\n    \"\"\"\n    train_indices, val_indices = train_test_split(range(len(dataset)), test_size=test_size, random_state=random_seed)\n    train_dataset = dataset.select(train_indices)\n    val_dataset = dataset.select(val_indices)\n    return train_dataset, val_dataset\n\n# Format the dataset\nformatted_dataset = format_dataset(dataset)\n\n# Split into train and validation datasets\ntrain_dataset, val_dataset = split_dataset(formatted_dataset)\n\n# Print a sample for verification\nprint(f\"Sample formatted training example:\\n{train_dataset[0]}\")\nprint(f\"Sample formatted validation example:\\n{val_dataset[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:03.779904Z","iopub.execute_input":"2024-12-23T04:22:03.780162Z","iopub.status.idle":"2024-12-23T04:22:04.027823Z","shell.execute_reply.started":"2024-12-23T04:22:03.780137Z","shell.execute_reply":"2024-12-23T04:22:04.026928Z"}},"outputs":[{"name":"stdout","text":"Sample formatted training example:\n{'text': 'D∆∞·ªõi ƒë√¢y l√† m·ªôt h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•, k√®m theo m·ªôt ƒë·∫ßu v√†o cung c·∫•p th√™m ng·ªØ c·∫£nh. Vi·∫øt m·ªôt ph·∫£n h·ªìi ho√†n ch·ªânh ƒë·ªÉ th·ª±c hi·ªán y√™u c·∫ßu.\\n\\n### H∆∞·ªõng d·∫´n: \\nL·∫≠p danh s√°ch c√°c th√†nh ph·∫ßn ch√≠nh c·ªßa Coca-Cola\\n\\n### ƒê·∫ßu v√†o: \\n\\n\\n### Ph·∫£n h·ªìi: \\n1. N∆∞·ªõc 2. ƒê∆∞·ªùng 3. Axit photphoric 4. Caffeine 5. H∆∞∆°ng li·ªáu 6. M√†u th·ª±c ph·∫©m 7. Ch·∫•t b·∫£o qu·∫£n\\n\\n'}\nSample formatted validation example:\n{'text': 'D∆∞·ªõi ƒë√¢y l√† m·ªôt h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•, k√®m theo m·ªôt ƒë·∫ßu v√†o cung c·∫•p th√™m ng·ªØ c·∫£nh. Vi·∫øt m·ªôt ph·∫£n h·ªìi ho√†n ch·ªânh ƒë·ªÉ th·ª±c hi·ªán y√™u c·∫ßu.\\n\\n### H∆∞·ªõng d·∫´n: \\nVi·∫øt m·ªôt c√¢u nh·∫•n m·∫°nh t·∫ßm quan tr·ªçng c·ªßa vi·ªác ƒë·ªçc s√°ch vƒÉn h·ªçc.\\n\\n### ƒê·∫ßu v√†o: \\n\\n\\n### Ph·∫£n h·ªìi: \\nƒê·ªçc s√°ch vƒÉn h·ªçc l√† ch√¨a kh√≥a ƒë·ªÉ m·ªü r·ªông ki·∫øn th·ª©c, ph√°t tri·ªÉn tr√≠ tu·ªá v√† nu√¥i d∆∞·ª°ng t√¢m h·ªìn.\\n\\n'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%capture\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:04.029130Z","iopub.execute_input":"2024-12-23T04:22:04.029534Z","iopub.status.idle":"2024-12-23T04:22:12.757726Z","shell.execute_reply.started":"2024-12-23T04:22:04.029490Z","shell.execute_reply":"2024-12-23T04:22:12.756421Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import evaluate\n\n# Load a metric\nmetric = evaluate.load(\"accuracy\") \n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Convert logits to predicted token indices\n    predictions = logits.argmax(axis=-1)\n\n    # Mask out ignored labels (e.g., -100)\n    valid_indices = labels != -100\n\n    # Flatten predictions and labels while filtering valid indices\n    predictions = predictions[valid_indices]\n    labels = labels[valid_indices]\n\n    print(\"Predictions:\", predictions)\n    print(\"Labels:\", labels)\n\n    # Compute the metric\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:12.759258Z","iopub.execute_input":"2024-12-23T04:22:12.759632Z","iopub.status.idle":"2024-12-23T04:22:13.444878Z","shell.execute_reply.started":"2024-12-23T04:22:12.759601Z","shell.execute_reply":"2024-12-23T04:22:13.443983Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d509bbdd6f1b4d3dac38f8e60f6aed24"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:13.446142Z","iopub.execute_input":"2024-12-23T04:22:13.446437Z","iopub.status.idle":"2024-12-23T04:22:13.450459Z","shell.execute_reply.started":"2024-12-23T04:22:13.446411Z","shell.execute_reply":"2024-12-23T04:22:13.449513Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# th·ª≠ instruction finetuning\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel.resize_token_embeddings(len(tokenizer))\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    args=SFTConfig(\n        output_dir=\"/tmp\",\n        num_train_epochs=1,\n        per_device_train_batch_size=1,\n        per_device_eval_batch_size=1,\n        gradient_accumulation_steps=10,\n        evaluation_strategy=\"steps\",\n        eval_steps=50,\n        fp16=True, \n        eval_accumulation_steps=4, \n    ),\n    formatting_func=None,\n    data_collator=collator,\n)\n\nimport torch\ntorch.cuda.empty_cache()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:32:46.590917Z","iopub.execute_input":"2024-12-23T04:32:46.591695Z","iopub.status.idle":"2024-12-23T04:41:35.540648Z","shell.execute_reply.started":"2024-12-23T04:32:46.591641Z","shell.execute_reply":"2024-12-23T04:41:35.539744Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b72767e04d8436c9e36f27f207e57df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/238 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc8ffc00ca02467da757d620f3d4afff"}},"metadata":{}},{"name":"stderr","text":"A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [213/213 08:47, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>1.855463</td>\n      <td>0.042103</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>1.800313</td>\n      <td>0.040584</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>No log</td>\n      <td>1.779424</td>\n      <td>0.040837</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>1.771594</td>\n      <td>0.040837</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Predictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 7843 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=213, training_loss=1.750956503997946, metrics={'train_runtime': 527.7113, 'train_samples_per_second': 4.053, 'train_steps_per_second': 0.404, 'total_flos': 140926224384000.0, 'train_loss': 1.750956503997946, 'epoch': 0.9957924263674615})"},"metadata":{}}],"execution_count":16}]}