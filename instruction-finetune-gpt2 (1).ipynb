{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --q datasets\n!pip install --q --upgrade trl\n!pip install --upgrade accelerate\n!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:20:32.801632Z","iopub.execute_input":"2024-12-23T04:20:32.801973Z","iopub.status.idle":"2024-12-23T04:21:08.510544Z","shell.execute_reply.started":"2024-12-23T04:20:32.801939Z","shell.execute_reply":"2024-12-23T04:21:08.509663Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nCollecting accelerate\n  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.26.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.1.1\n    Uninstalling accelerate-1.1.1:\n      Successfully uninstalled accelerate-1.1.1\nSuccessfully installed accelerate-1.2.1\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained('NlpHUST/gpt2-vietnamese')\nmodel = GPT2LMHeadModel.from_pretrained('NlpHUST/gpt2-vietnamese')\n\ntext = \"Việt Nam là quốc gia có\"\ninput_ids = tokenizer.encode(text, return_tensors='pt')\nmax_length = 100\n\nsample_outputs = model.generate(input_ids,pad_token_id=tokenizer.eos_token_id,\n                                   do_sample=True,\n                                   max_length=max_length,\n                                   min_length=max_length,\n                                   top_k=40,\n                                   num_beams=5,\n                                   early_stopping=True,\n                                   no_repeat_ngram_size=2,\n                                   num_return_sequences=3)\n\nfor i, sample_output in enumerate(sample_outputs):\n    print(\">> Generated text {}\\n\\n{}\".format(i+1, tokenizer.decode(sample_output.tolist())))\n    print('\\n---')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:08.512856Z","iopub.execute_input":"2024-12-23T04:21:08.513248Z","iopub.status.idle":"2024-12-23T04:21:38.742599Z","shell.execute_reply.started":"2024-12-23T04:21:08.513208Z","shell.execute_reply":"2024-12-23T04:21:38.741690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfcbf23ce08d4c94852d7775693bfed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/854k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b085103e237f457397afc8e0069525f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/512k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1750ef5d0484e998511f677a09f21f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2974f88de2425ead82444afeeb7a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6731727014142bfbafa91ed683627ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36bb844d0acd4b2f8d33a47c4b2e1bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9ee439e4934c4491d443415a7a9d4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d849175b43064f36b0d5e34844a0cb4b"}},"metadata":{}},{"name":"stdout","text":">> Generated text 1\n\nViệt Nam là quốc gia có nền kinh tế hàng đầu trên thế giới và được đánh giá là một trong những thị trường xuất khẩu lớn nhất của Việt Nam.\nTheo số liệu thống kê của Tổng cục Hải quan, trong 6 tháng đầu năm 2018, tổng kim ngạch xuất nhập khẩu hàng hóa của cả nước ước đạt 2,12 tỷ USD, tăng 11,4% so với cùng kỳ năm 2017. Trong đó, xuất siêu đạt 1,6 tỷ đô la Mỹ, chiếm 13,2\n\n---\n>> Generated text 2\n\nViệt Nam là quốc gia có nền kinh tế hàng đầu trên thế giới và được đánh giá là một trong những thị trường xuất khẩu lớn nhất của Việt Nam.\nTheo số liệu thống kê của Tổng cục Hải quan, trong 6 tháng đầu năm 2018, tổng kim ngạch xuất nhập khẩu hàng hóa của cả nước ước đạt 2,12 tỷ USD, tăng 11,4% so với cùng kỳ năm 2017. Trong đó, xuất siêu đạt 1,6 tỷ đô la Mỹ, chiếm 5,8\n\n---\n>> Generated text 3\n\nViệt Nam là quốc gia có nền kinh tế hàng đầu trên thế giới và được đánh giá là một trong những thị trường xuất khẩu lớn nhất của Việt Nam.\nTheo số liệu thống kê của Tổng cục Hải quan, trong 6 tháng đầu năm 2018, tổng kim ngạch xuất nhập khẩu hàng hóa của cả nước ước đạt 2,12 tỷ USD, tăng 11,4% so với cùng kỳ năm 2017. Trong đó, xuất siêu đạt 1,6 tỷ đô la Mỹ, chiếm 5,7\n\n---\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Đếm số lượng tham số của model\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams_count = sum([torch.numel(p) for p in model_parameters])\n\nprint(f\"Total trainable parameters: {params_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:38.743710Z","iopub.execute_input":"2024-12-23T04:21:38.744201Z","iopub.status.idle":"2024-12-23T04:21:38.750399Z","shell.execute_reply.started":"2024-12-23T04:21:38.744173Z","shell.execute_reply":"2024-12-23T04:21:38.749546Z"}},"outputs":[{"name":"stdout","text":"Total trainable parameters: 124439808\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\n\nfrom datasets import load_dataset\nopen_instruct_dataset = load_dataset(\"5CD-AI/Vietnamese-Ecommerce-Alpaca\", split=\"train\")\n\nmax_seq_len = 100\ntotal_data_points = len(open_instruct_dataset)\nsample_size = 10000\nrandom_indices = random.sample(range(total_data_points), sample_size)\n\n\n\n# filter dataset to rows where the entire context length is less than or equal to max_seq_len,\n# which is the size of the DeciLM-6B context window\n\nopen_instruct_dataset = open_instruct_dataset.select(random_indices)\n\ndataset = open_instruct_dataset.filter(\n    lambda example: (len(tokenizer(example.get(\"instruction\", \"\"), truncation=True)[\"input_ids\"]) +\n                     len(tokenizer(example.get(\"input\", \"\"), truncation=True)[\"input_ids\"]) +\n                     len(tokenizer(example.get(\"output\", \"\"), truncation=True)[\"input_ids\"])) <= max_seq_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:38.751761Z","iopub.execute_input":"2024-12-23T04:21:38.752116Z","iopub.status.idle":"2024-12-23T04:21:59.302798Z","shell.execute_reply.started":"2024-12-23T04:21:38.752078Z","shell.execute_reply":"2024-12-23T04:21:59.301866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ecommerce_alpaca.json:   0%|          | 0.00/84.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c411bb3045445ca4cf84ed7d15fb1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/69303 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9c67f815334ce6bbbac0f4c41a6223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ddde04fe6a3404bb66e47668a537c7d"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:59.304855Z","iopub.execute_input":"2024-12-23T04:21:59.305131Z","iopub.status.idle":"2024-12-23T04:21:59.310888Z","shell.execute_reply.started":"2024-12-23T04:21:59.305104Z","shell.execute_reply":"2024-12-23T04:21:59.310002Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'instruction', 'input'],\n    num_rows: 2377\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def format_row_as_instruction_prompt(example):\n    has_input = example.get('input', None) is not None\n\n    if has_input:\n        primer_prompt = (\"Dưới đây là một hướng dẫn mô tả nhiệm vụ, kèm theo một đầu vào \"\n                         \"cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn chỉnh để thực hiện yêu cầu.\")\n        input_template = f\"### Đầu vào: \\n{example['input']}\\n\\n\"\n    else:\n        primer_prompt = (\"Dưới đây là một hướng dẫn mô tả nhiệm vụ. \"\n                         \"Viết một phản hồi hoàn chỉnh để thực hiện yêu cầu.\")\n        input_template = \"\"\n\n    instruction_template = f\"### Hướng dẫn: \\n{example['instruction']}\\n\\n\"\n\n    if example.get('output', None):\n        response_template = f\"### Phản hồi: \\n{example['output']}\\n\\n\"\n    else:\n        response_template = \"\"\n\n    # Wrap the resulting string in a list\n    return [f\"{primer_prompt}\\n\\n{instruction_template}{input_template}{response_template}\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:21:59.311894Z","iopub.execute_input":"2024-12-23T04:21:59.312147Z","iopub.status.idle":"2024-12-23T04:22:01.311567Z","shell.execute_reply.started":"2024-12-23T04:21:59.312122Z","shell.execute_reply":"2024-12-23T04:22:01.310606Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(format_row_as_instruction_prompt(dataset[0])[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:01.312930Z","iopub.execute_input":"2024-12-23T04:22:01.313651Z","iopub.status.idle":"2024-12-23T04:22:01.323790Z","shell.execute_reply.started":"2024-12-23T04:22:01.313610Z","shell.execute_reply":"2024-12-23T04:22:01.322850Z"}},"outputs":[{"name":"stdout","text":"Dưới đây là một hướng dẫn mô tả nhiệm vụ, kèm theo một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn chỉnh để thực hiện yêu cầu.\n\n### Hướng dẫn: \nKết hợp hai mảng sau không có trùng lặp [\"Dây giày thể thao\", \"Miếng lót giày\", \"Bàn chải đánh giày\"] và [\"Miếng lót giày\", \"Bàn chải đánh giày\", \"Móc khóa giày\"]\n\n### Đầu vào: \n\n\n### Phản hồi: \nSau khi kết hợp hai mảng mà không có sự trùng lặp, mảng thu được là: [\"Dây giày thể thao\", \"Miếng lót giày\", \"Bàn chải đánh giày\", \"Móc khóa giày\"]\n\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n\nresponse_template = \"### Phản hồi:\"\ncollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:01.325114Z","iopub.execute_input":"2024-12-23T04:22:01.325423Z","iopub.status.idle":"2024-12-23T04:22:03.762713Z","shell.execute_reply.started":"2024-12-23T04:22:01.325398Z","shell.execute_reply":"2024-12-23T04:22:03.761789Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:03.763823Z","iopub.execute_input":"2024-12-23T04:22:03.764092Z","iopub.status.idle":"2024-12-23T04:22:03.778852Z","shell.execute_reply.started":"2024-12-23T04:22:03.764065Z","shell.execute_reply":"2024-12-23T04:22:03.778150Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.1, random_state=42)\ntrain_dataset = dataset.select(train_indices)\nval_dataset = dataset.select(val_indices)\n\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Format the Dataset\ndef format_dataset(dataset):\n    \"\"\"\n    Format each row in the dataset using the format_row_as_instruction_prompt function\n    and return a Hugging Face Dataset object.\n    \"\"\"\n    # Create a dictionary to store formatted data\n    formatted_data = {\"text\": []}\n\n    for example in dataset:\n        formatted = format_row_as_instruction_prompt(example)[0]\n        formatted_data[\"text\"].append(formatted)\n\n    # Convert the dictionary into a Hugging Face Dataset\n    return Dataset.from_dict(formatted_data)\n\n\n# Step 2: Split the Dataset\ndef split_dataset(dataset, test_size=0.1, random_seed=42):\n    \"\"\"\n    Split the dataset into training and validation sets.\n    \"\"\"\n    train_indices, val_indices = train_test_split(range(len(dataset)), test_size=test_size, random_state=random_seed)\n    train_dataset = dataset.select(train_indices)\n    val_dataset = dataset.select(val_indices)\n    return train_dataset, val_dataset\n\n# Format the dataset\nformatted_dataset = format_dataset(dataset)\n\n# Split into train and validation datasets\ntrain_dataset, val_dataset = split_dataset(formatted_dataset)\n\n# Print a sample for verification\nprint(f\"Sample formatted training example:\\n{train_dataset[0]}\")\nprint(f\"Sample formatted validation example:\\n{val_dataset[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:03.779904Z","iopub.execute_input":"2024-12-23T04:22:03.780162Z","iopub.status.idle":"2024-12-23T04:22:04.027823Z","shell.execute_reply.started":"2024-12-23T04:22:03.780137Z","shell.execute_reply":"2024-12-23T04:22:04.026928Z"}},"outputs":[{"name":"stdout","text":"Sample formatted training example:\n{'text': 'Dưới đây là một hướng dẫn mô tả nhiệm vụ, kèm theo một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn chỉnh để thực hiện yêu cầu.\\n\\n### Hướng dẫn: \\nLập danh sách các thành phần chính của Coca-Cola\\n\\n### Đầu vào: \\n\\n\\n### Phản hồi: \\n1. Nước 2. Đường 3. Axit photphoric 4. Caffeine 5. Hương liệu 6. Màu thực phẩm 7. Chất bảo quản\\n\\n'}\nSample formatted validation example:\n{'text': 'Dưới đây là một hướng dẫn mô tả nhiệm vụ, kèm theo một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn chỉnh để thực hiện yêu cầu.\\n\\n### Hướng dẫn: \\nViết một câu nhấn mạnh tầm quan trọng của việc đọc sách văn học.\\n\\n### Đầu vào: \\n\\n\\n### Phản hồi: \\nĐọc sách văn học là chìa khóa để mở rộng kiến thức, phát triển trí tuệ và nuôi dưỡng tâm hồn.\\n\\n'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%capture\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:04.029130Z","iopub.execute_input":"2024-12-23T04:22:04.029534Z","iopub.status.idle":"2024-12-23T04:22:12.757726Z","shell.execute_reply.started":"2024-12-23T04:22:04.029490Z","shell.execute_reply":"2024-12-23T04:22:12.756421Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import evaluate\n\n# Load a metric\nmetric = evaluate.load(\"accuracy\") \n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Convert logits to predicted token indices\n    predictions = logits.argmax(axis=-1)\n\n    # Mask out ignored labels (e.g., -100)\n    valid_indices = labels != -100\n\n    # Flatten predictions and labels while filtering valid indices\n    predictions = predictions[valid_indices]\n    labels = labels[valid_indices]\n\n    print(\"Predictions:\", predictions)\n    print(\"Labels:\", labels)\n\n    # Compute the metric\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:12.759258Z","iopub.execute_input":"2024-12-23T04:22:12.759632Z","iopub.status.idle":"2024-12-23T04:22:13.444878Z","shell.execute_reply.started":"2024-12-23T04:22:12.759601Z","shell.execute_reply":"2024-12-23T04:22:13.443983Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d509bbdd6f1b4d3dac38f8e60f6aed24"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:22:13.446142Z","iopub.execute_input":"2024-12-23T04:22:13.446437Z","iopub.status.idle":"2024-12-23T04:22:13.450459Z","shell.execute_reply.started":"2024-12-23T04:22:13.446411Z","shell.execute_reply":"2024-12-23T04:22:13.449513Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# thử instruction finetuning\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel.resize_token_embeddings(len(tokenizer))\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    args=SFTConfig(\n        output_dir=\"/tmp\",\n        num_train_epochs=1,\n        per_device_train_batch_size=1,\n        per_device_eval_batch_size=1,\n        gradient_accumulation_steps=10,\n        evaluation_strategy=\"steps\",\n        eval_steps=50,\n        fp16=True, \n        eval_accumulation_steps=4, \n    ),\n    formatting_func=None,\n    data_collator=collator,\n)\n\nimport torch\ntorch.cuda.empty_cache()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T04:32:46.590917Z","iopub.execute_input":"2024-12-23T04:32:46.591695Z","iopub.status.idle":"2024-12-23T04:41:35.540648Z","shell.execute_reply.started":"2024-12-23T04:32:46.591641Z","shell.execute_reply":"2024-12-23T04:41:35.539744Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b72767e04d8436c9e36f27f207e57df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/238 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc8ffc00ca02467da757d620f3d4afff"}},"metadata":{}},{"name":"stderr","text":"A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [213/213 08:47, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>1.855463</td>\n      <td>0.042103</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>1.800313</td>\n      <td>0.040584</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>No log</td>\n      <td>1.779424</td>\n      <td>0.040837</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>1.771594</td>\n      <td>0.040837</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Predictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 7843 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\nPredictions: [ 203 1978 1080 ...  203  203  203]\nLabels: [ 225  203 7843 ...   18  203  203]\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=213, training_loss=1.750956503997946, metrics={'train_runtime': 527.7113, 'train_samples_per_second': 4.053, 'train_steps_per_second': 0.404, 'total_flos': 140926224384000.0, 'train_loss': 1.750956503997946, 'epoch': 0.9957924263674615})"},"metadata":{}}],"execution_count":16}]}